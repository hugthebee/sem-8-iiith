{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514260b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256, scale=(0.7,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "remove = {95, 145, 146, 158, 159, 160, 161}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "def inverse_transform_coords(coords_tensor):\n",
    "  coords_np = coords_tensor.detach().cpu().numpy()\n",
    "  return scaler.inverse_transform(coords_np)\n",
    "\n",
    "def compute_real_world_mse(pred_coords, true_coords):\n",
    "  return mean_squared_error(true_coords, pred_coords)\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    df = df[(df['longitude'] >= 100000) & (df['longitude'] <= 700000)]\n",
    "    df = df[(df['latitude'] >= 50000) & (df['latitude'] <= 250000)]\n",
    "    # df = df[(df['longitude'] >= 140000) & (df['longitude'] <= 150000)]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, images_dir, transform=None, val=False, mse=False, apply_cleaning=True):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        if apply_cleaning:\n",
    "            self.df = clean_dataframe(self.df)\n",
    "\n",
    "        if mse:\n",
    "            self.df = self.df[~self.df.index.isin(remove)].reset_index(drop=True)\n",
    "\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        coords = self.df[['latitude', 'longitude']].values\n",
    "        self.scaled_coords = scaler.fit_transform(coords) if not val else scaler.transform(coords)\n",
    "\n",
    "        \n",
    "        if not val:\n",
    "            self.plot_scaled_coordinates()\n",
    "\n",
    "    def plot_scaled_coordinates(self):\n",
    "        latitudes = self.scaled_coords[:, 0]\n",
    "        longitudes = self.scaled_coords[:, 1]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(longitudes, latitudes, c='blue', alpha=0.5)\n",
    "        plt.title(\"Scaled Latitude vs Longitude\")\n",
    "        plt.xlabel(\"Longitude\")\n",
    "        plt.ylabel(\"Latitude\")\n",
    "        plt.show()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.images_dir, row['filename'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if img.size != (256, 256):\n",
    "            img = img.resize((256, 256), Image.BILINEAR)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        coords = torch.tensor(self.scaled_coords[idx], dtype=torch.float32)\n",
    "        angle = torch.tensor(row['angle'], dtype=torch.float32)\n",
    "        region = torch.tensor(row['Region_ID'] - 1, dtype=torch.long)\n",
    "\n",
    "        return img, region, coords, angle\n",
    "\n",
    "train_data = ImageDataset(\"/content/drive/MyDrive/smai_project/labels_train_updated.csv\",\n",
    "                          \"/content/images_train\", transform=train_transform, mse=False)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "val_data = ImageDataset(\"/content/drive/MyDrive/smai_project/labels_val_updated.csv\",\n",
    "                        \"/content/images_val\", transform=val_transform, mse=True, apply_cleaning = False)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "class MeanAngularError(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        diff = torch.remainder(torch.abs(y_pred - y_true), 360)\n",
    "        ang_err = torch.minimum(diff, 360 - diff)\n",
    "        return torch.mean(ang_err)\n",
    "\n",
    "class ImprovedResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet50(pretrained=True)\n",
    "        # freeze all except layer4\n",
    "        for name, p in base.named_parameters():\n",
    "            if 'layer3' in name or 'layer4' in name or 'fc' in name:\n",
    "                p.requires_grad = True\n",
    "            else:\n",
    "                p.requires_grad = False\n",
    "        base.fc = nn.Identity()\n",
    "        self.backbone = base\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.region = nn.Linear(2048, 15)\n",
    "        self.coord  = nn.Linear(2048, 2)\n",
    "        self.coord_head = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "        self.angle  = nn.Linear(2048, 1)\n",
    "\n",
    "        self.region_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        self.coord_criterion  = nn.MSELoss()\n",
    "        self.angle_criterion  = MeanAngularError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x).squeeze()\n",
    "        f = self.dropout(f)\n",
    "        return self.region(f), self.coord_head(f), self.angle(f).squeeze(1)\n",
    "\n",
    "    def evaluate(self, val_loader, device):\n",
    "        self.eval()\n",
    "        correct, sum_ang_err = 0, 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, regions, coords, angles in val_loader:\n",
    "                imgs, regions, coords, angles = imgs.to(device), regions.to(device), coords.to(device), angles.to(device)\n",
    "                pr, pc, pa = self(imgs)\n",
    "\n",
    "                correct += (pr.argmax(dim=1) == regions).sum().item()\n",
    "                sum_ang_err += self.angle_criterion(pa, angles).item() * imgs.size(0)\n",
    "\n",
    "                all_preds.append(pc)\n",
    "                all_targets.append(coords)\n",
    "\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        preds_real = inverse_transform_coords(all_preds)\n",
    "        targets_real = inverse_transform_coords(all_targets)\n",
    "\n",
    "        lat_pred, lon_pred = preds_real[:, 0], preds_real[:, 1]\n",
    "        lat_true, lon_true = targets_real[:, 0], targets_real[:, 1]\n",
    "\n",
    "        lat_mse = mean_squared_error(lat_true, lat_pred)\n",
    "        lon_mse = mean_squared_error(lon_true, lon_pred)\n",
    "        avg_mse = 0.5 * (lat_mse + lon_mse)\n",
    "\n",
    "        n = len(val_loader.dataset)\n",
    "        print(f\"Val Acc: {correct/n:.4f}, Coord Avg MSE (real scale): {avg_mse:.4f}, \"\n",
    "              f\"(Lat MSE: {lat_mse:.4f}, Lon MSE: {lon_mse:.4f}), Mean Angular Error: {sum_ang_err/n:.4f}\\n\")\n",
    "\n",
    "\n",
    "    def train_model(self, train_loader, val_loader, epochs=15, lr=1e-5, device='cuda'):\n",
    "        self.to(device)\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "        for ep in range(1, epochs+1):\n",
    "            self.train(); total=0\n",
    "            for imgs, regs, coords, angs in train_loader:\n",
    "                imgs, regs, coords, angs = [t.to(device) for t in (imgs, regs, coords, angs)]\n",
    "                opt.zero_grad()\n",
    "                pr, pc, pa = self(imgs)\n",
    "                l = 2*self.region_criterion(pr, regs)\n",
    "                l+= 0.5*self.coord_criterion(pc, coords)\n",
    "                l+= 0.05*self.angle_criterion(pa, angs)\n",
    "                l.backward(); opt.step()\n",
    "                total+= l.item()*imgs.size(0)\n",
    "            print(f\"Epoch{ep} TrainLoss:{total/len(train_loader.dataset):.4f} LR:{sched.get_last_lr()[0]:.1e}\")\n",
    "            sched.step()\n",
    "            self.evaluate(val_loader, device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImprovedResNet()\n",
    "model.train_model(train_loader, val_loader, epochs=20, lr=1e-4, device=device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

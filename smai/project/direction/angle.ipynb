{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T09:06:00.007056Z",
     "iopub.status.busy": "2025-05-05T09:06:00.006860Z",
     "iopub.status.idle": "2025-05-05T09:06:12.689307Z",
     "shell.execute_reply": "2025-05-05T09:06:12.688735Z",
     "shell.execute_reply.started": "2025-05-05T09:06:00.007030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T10:59:16.428467Z",
     "iopub.status.busy": "2025-05-05T10:59:16.428306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 231MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RESNET ===\n",
      "Epoch 1/30 - Train MAAE: 0.0113\n",
      "\n",
      "Final Validation Accuracy (1 / (1 + MAAE)): 0.0118\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "class MeanAbsoluteAngularError(nn.Module):\n",
    "    def forward(self, pred, target):\n",
    "        diff = torch.abs(pred - target) % 360\n",
    "        angular_error = torch.minimum(diff, 360 - diff)\n",
    "        return angular_error.mean()\n",
    "\n",
    "\n",
    "class CommonModel(nn.Module):\n",
    "    def __init__(self, num_regions):\n",
    "        super().__init__()\n",
    "        base = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        for param in base.parameters():\n",
    "            param.requires_grad = False\n",
    "        base.fc = nn.Identity()\n",
    "        self.backbone = base\n",
    "\n",
    "        self.shared_head = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.angle_head = nn.Linear(256, 1)\n",
    "        self.coord_head = nn.Linear(256, 2)\n",
    "        self.region_head = nn.Linear(256, num_regions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        feat = self.shared_head(feat)\n",
    "        angle = self.angle_head(feat).squeeze(1)\n",
    "        coords = self.coord_head(feat)\n",
    "        region = self.region_head(feat)\n",
    "        return angle, coords, region\n",
    "\n",
    "    def evaluate(self, val_loader, device):\n",
    "        self.eval()\n",
    "        criterion_angle = MeanAbsoluteAngularError()\n",
    "        total_maae = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, angle_targets, coord_targets, region_targets in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                angle_targets = angle_targets.to(device)\n",
    "\n",
    "                angle_preds, _, _ = self(imgs)\n",
    "                maae = criterion_angle(angle_preds, angle_targets)\n",
    "                total_maae += maae.item() * imgs.size(0)\n",
    "                total_samples += imgs.size(0)\n",
    "\n",
    "        final_maae = total_maae / total_samples\n",
    "        accuracy = 1 / (1 + final_maae)\n",
    "        print(f\"\\nFinal Validation Accuracy (1 / (1 + MAAE)): {accuracy:.4f}\")\n",
    "\n",
    "    def train_model(self, train_loader, val_loader, epochs, lr, device='cuda', angle_weight=1.0, coord_weight=0.3, region_weight=0.3):\n",
    "        self.to(device)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion_angle = MeanAbsoluteAngularError()\n",
    "        criterion_coord = nn.MSELoss()\n",
    "        criterion_region = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for imgs, angle_targets, coord_targets, region_targets in train_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                angle_targets = angle_targets.to(device)\n",
    "                coord_targets = coord_targets.to(device)\n",
    "                region_targets = region_targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                angle_preds, coord_preds, region_preds = self(imgs)\n",
    "\n",
    "                loss_angle = criterion_angle(angle_preds, angle_targets)\n",
    "                loss_coords = criterion_coord(coord_preds, coord_targets)\n",
    "                loss_region = criterion_region(region_preds, region_targets)\n",
    "\n",
    "                loss = angle_weight * loss_angle + coord_weight * loss_coords + region_weight * loss_region\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader.dataset)\n",
    "            print(f\"Epoch {epoch}/{epochs} - Total Weighted Loss: {avg_loss:.4f}\")\n",
    "            self.evaluate(val_loader, device)\n",
    "            \n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, images_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.images_dir, row['filename'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        angle = torch.tensor(row['angle'], dtype=torch.float)\n",
    "        coords = torch.tensor([row['latitude'], row['longitude']], dtype=torch.float)\n",
    "        region_id = torch.tensor(row['region_id'], dtype=torch.long)\n",
    "        return img, angle, coords, region_id\n",
    "        \n",
    "train_data = ImageDataset(\"/kaggle/input/smai-project/labels_train_updated.csv\",\n",
    "                                \"/kaggle/input/smai-project/images_train/images_train\", \n",
    "                                transform=transform_train)\n",
    "\n",
    "val_data = ImageDataset(\"/kaggle/input/smai-project/labels_val_updated.csv\",\n",
    "                              \"/kaggle/input/smai-project/images_val/images_val\", \n",
    "                              transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "num_regions = 15\n",
    "model = CommonModel(num_regions=num_regions)\n",
    "model.train_model(train_loader, val_loader, epochs=30, lr=1e-4, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_tensor = model.predict_angles(val_loader, device='cuda')\n",
    "val_preds_np = val_preds_tensor.numpy() % 360\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, images_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.filenames = sorted(os.listdir(images_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        img_path = os.path.join(self.images_dir, filename)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, filename\n",
    "\n",
    "test_dataset = TestImageDataset(\"/kaggle/input/smai-test/images_test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for imgs, _ in test_loader:\n",
    "        imgs = imgs.to('cuda')\n",
    "        outputs = model(imgs)\n",
    "        test_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "test_preds_np = np.array(test_preds) % 360\n",
    "ids = np.arange(738)\n",
    "angles = np.round(np.concatenate([val_preds_np, test_preds_np])).astype(int) % 360\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'angle': angles\n",
    "})\n",
    "submission_df.to_csv(\"2021102007_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7080690,
     "sourceId": 11320862,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7321619,
     "sourceId": 11666063,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
